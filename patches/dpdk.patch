diff --git a/QDMA/DPDK/drivers/net/qdma/qdma_access/eqdma_soft_access/eqdma_soft_access.c b/QDMA/DPDK/drivers/net/qdma/qdma_access/eqdma_soft_access/eqdma_soft_access.c
index 0332479..c0dbf37 100755
--- a/QDMA/DPDK/drivers/net/qdma/qdma_access/eqdma_soft_access/eqdma_soft_access.c
+++ b/QDMA/DPDK/drivers/net/qdma/qdma_access/eqdma_soft_access/eqdma_soft_access.c
@@ -2442,7 +2442,7 @@ int eqdma_set_default_global_csr(void *dev_hndl)
 		80, 96, 112, 128, 144, 160, 176, 192};
 	uint32_t buf_sz[QDMA_NUM_C2H_BUFFER_SIZES] = {4096, 256, 512, 1024,
 		2048, 3968, 4096, 4096, 4096, 4096, 4096, 4096, 4096, 8192,
-		9018, 16384};
+		9618, 16384};
 	struct qdma_dev_attributes dev_cap;
 	uint32_t eqdma_ip_version;
 
diff --git a/QDMA/DPDK/drivers/net/qdma/qdma_devops.c b/QDMA/DPDK/drivers/net/qdma/qdma_devops.c
index b53027f..9293c41 100755
--- a/QDMA/DPDK/drivers/net/qdma/qdma_devops.c
+++ b/QDMA/DPDK/drivers/net/qdma/qdma_devops.c
@@ -478,7 +478,7 @@ int qdma_dev_rx_queue_setup(struct rte_eth_dev *dev, uint16_t rx_queue_id,
 	/* Find Threshold index */
 	rxq->threshidx = index_of_array(qdma_dev->g_c2h_cnt_th,
 					QDMA_NUM_C2H_COUNTERS,
-					rx_conf->rx_thresh.wthresh);
+					rx_conf->rx_thresh.wthresh + 2);
 	if (rxq->threshidx < 0) {
 		PMD_DRV_LOG(WARNING, "Expected Threshold %d not found,"
 				" using the value %d at index 7\n",
@@ -1967,12 +1967,18 @@ static struct eth_dev_ops qdma_eth_dev_ops = {
 void qdma_dev_ops_init(struct rte_eth_dev *dev)
 {
 	dev->dev_ops = &qdma_eth_dev_ops;
-	if (rte_eal_process_type() == RTE_PROC_PRIMARY) {
-		qdma_set_rx_function(dev);
-		qdma_set_tx_function(dev);
-		dev->rx_queue_count = &qdma_dev_rx_queue_count;
-		dev->rx_descriptor_status = &qdma_dev_rx_descriptor_status;
-		dev->tx_descriptor_status = &qdma_dev_tx_descriptor_status;
-	}
+	/*
+		EXPERIMENTAL:
+		The following check to initialize the rx_* and tx_* only if the
+		process is PRIMARY has been disabled. We will initialize all functions
+		for both PRIMARY and SECONDARY.
+	*/
+	// if (rte_eal_process_type() == RTE_PROC_PRIMARY) {
+	qdma_set_rx_function(dev);
+	qdma_set_tx_function(dev);
+	dev->rx_queue_count = &qdma_dev_rx_queue_count;
+	dev->rx_descriptor_status = &qdma_dev_rx_descriptor_status;
+	dev->tx_descriptor_status = &qdma_dev_tx_descriptor_status;
+	// }
 }
 
diff --git a/QDMA/DPDK/drivers/net/qdma/qdma_rxtx.c b/QDMA/DPDK/drivers/net/qdma/qdma_rxtx.c
index bf51411..0f00a4b 100755
--- a/QDMA/DPDK/drivers/net/qdma/qdma_rxtx.c
+++ b/QDMA/DPDK/drivers/net/qdma/qdma_rxtx.c
@@ -41,12 +41,6 @@
 #include "qdma_rxtx.h"
 #include "qdma_devops.h"
 
-#if defined RTE_ARCH_X86_64
-#include <immintrin.h>
-#include <emmintrin.h>
-#define RTE_QDMA_DESCS_PER_LOOP (2)
-#endif
-
 /**
  * Poll the QDMA engine for transfer completion.
  *
@@ -132,8 +126,6 @@ int qdma_extract_st_cmpt_info(void *ul_cmpt_entry, void *cmpt_info)
 	cmpt_data = (union qdma_ul_st_cmpt_ring *)(cmpt_info);
 
 	cmpt_data->data = cmpt_desc->data;
-	if (unlikely(!cmpt_desc->desc_used))
-		cmpt_data->length = 0;
 
 	return 0;
 }
@@ -1391,33 +1383,33 @@ uint16_t qdma_xmit_pkts(void *tx_queue, struct rte_mbuf **tx_pkts,
 void __rte_cold
 qdma_set_tx_function(struct rte_eth_dev *dev)
 {
-	struct qdma_pci_dev *qdma_dev = dev->data->dev_private;
-
-	if (rte_vect_get_max_simd_bitwidth() >= RTE_VECT_SIMD_128) {
-		PMD_DRV_LOG(DEBUG, "Using Vector Tx (port %d).",
-			dev->data->port_id);
-		qdma_dev->tx_vec_allowed = true;
-		dev->tx_pkt_burst = qdma_xmit_pkts_vec;
-	} else {
+	/* struct qdma_pci_dev *qdma_dev = dev->data->dev_private; */
+
+	/* if (rte_vect_get_max_simd_bitwidth() >= RTE_VECT_SIMD_128) { */
+	/* 	PMD_DRV_LOG(DEBUG, "Using Vector Tx (port %d).", */
+	/* 		dev->data->port_id); */
+	/* 	qdma_dev->tx_vec_allowed = true; */
+	/* 	dev->tx_pkt_burst = qdma_xmit_pkts_vec; */
+	/* } else { */
 		PMD_DRV_LOG(DEBUG, "Normal Rx will be used on port %d.",
 				dev->data->port_id);
 		dev->tx_pkt_burst = qdma_xmit_pkts;
-	}
+	/* } */
 }
 
 void __rte_cold
 qdma_set_rx_function(struct rte_eth_dev *dev)
 {
-	struct qdma_pci_dev *qdma_dev = dev->data->dev_private;
-
-	if (rte_vect_get_max_simd_bitwidth() >= RTE_VECT_SIMD_128) {
-		PMD_DRV_LOG(DEBUG, "Using Vector Rx (port %d).",
-			dev->data->port_id);
-		qdma_dev->rx_vec_allowed = true;
-		dev->rx_pkt_burst = qdma_recv_pkts_vec;
-	} else {
+	/* struct qdma_pci_dev *qdma_dev = dev->data->dev_private; */
+
+	/* if (rte_vect_get_max_simd_bitwidth() >= RTE_VECT_SIMD_128) { */
+	/* 	PMD_DRV_LOG(DEBUG, "Using Vector Rx (port %d).", */
+	/* 		dev->data->port_id); */
+	/* 	qdma_dev->rx_vec_allowed = true; */
+	/* 	dev->rx_pkt_burst = qdma_recv_pkts_vec; */
+	/* } else { */
 		PMD_DRV_LOG(DEBUG, "Normal Rx will be used on port %d.",
 				dev->data->port_id);
 		dev->rx_pkt_burst = qdma_recv_pkts;
-	}
+	/* } */
 }
diff --git a/QDMA/DPDK/drivers/net/qdma/qdma_user.c b/QDMA/DPDK/drivers/net/qdma/qdma_user.c
index a487de6..e93ae58 100755
--- a/QDMA/DPDK/drivers/net/qdma/qdma_user.c
+++ b/QDMA/DPDK/drivers/net/qdma/qdma_user.c
@@ -59,12 +59,10 @@ int qdma_ul_extract_st_cmpt_info(void *ul_cmpt_entry, void *cmpt_info)
 	cmpt_desc = (union qdma_ul_st_cmpt_ring *)(ul_cmpt_entry);
 	cmpt_data = (union qdma_ul_st_cmpt_ring *)(cmpt_info);
 
-	if (unlikely(cmpt_desc->err || cmpt_desc->data_frmt))
+	if (unlikely(cmpt_desc->err))
 		return -1;
 
 	cmpt_data->data = cmpt_desc->data;
-	if (unlikely(!cmpt_desc->desc_used))
-		cmpt_data->length = 0;
 
 	return 0;
 }
@@ -80,7 +78,7 @@ int qdma_ul_extract_st_cmpt_info(void *ul_cmpt_entry, void *cmpt_info)
  */
 uint16_t qdma_ul_get_cmpt_pkt_len(void *ul_cmpt_entry)
 {
-	return ((union qdma_ul_st_cmpt_ring *)ul_cmpt_entry)->length;
+	return ((union qdma_ul_st_cmpt_ring *)ul_cmpt_entry)->pkt_len;
 }
 
 /**
@@ -173,36 +171,10 @@ int qdma_ul_update_st_h2c_desc(void *qhndl, uint64_t q_offloads,
 {
 	(void)q_offloads;
 	struct qdma_ul_st_h2c_desc *desc_info;
-	int nsegs = mb->nb_segs;
-	int pkt_segs = nsegs;
-
-	if (nsegs == 1) {
-		desc_info = get_st_h2c_desc(qhndl);
-		desc_info->len = rte_pktmbuf_data_len(mb);
-		desc_info->pld_len = desc_info->len;
-		desc_info->src_addr = mb->buf_iova + mb->data_off;
-		desc_info->flags = (S_H2C_DESC_F_SOP | S_H2C_DESC_F_EOP);
-		desc_info->cdh_flags = 0;
-		return 0;
-	}
-
-	while (nsegs && mb) {
-		desc_info = get_st_h2c_desc(qhndl);
-
-		desc_info->len = rte_pktmbuf_data_len(mb);
-		desc_info->pld_len = desc_info->len;
-		desc_info->src_addr = mb->buf_iova + mb->data_off;
-		desc_info->flags = 0;
-
-		desc_info->flags |= (nsegs == pkt_segs) ? S_H2C_DESC_F_SOP : 0;
-		desc_info->flags |= (nsegs == 1) ? S_H2C_DESC_F_EOP : 0;
-
-		desc_info->cdh_flags = 0;
-
-		nsegs--;
-		mb = mb->next;
-	}
-
+    desc_info = get_st_h2c_desc(qhndl);
+    desc_info->len = rte_pktmbuf_data_len(mb);
+    desc_info->meta_pkt_len = desc_info->len;
+    desc_info->src_addr = mb->buf_iova + mb->data_off;
 	return 0;
 }
 
@@ -283,7 +255,7 @@ int qdma_ul_process_immediate_data(void *cmpt_entry, uint16_t cmpt_desc_len,
 	struct qdma_ul_cmpt_ring *cmpt_desc =
 			(struct qdma_ul_cmpt_ring *)(cmpt_entry);
 
-	if (unlikely(cmpt_desc->err || cmpt_desc->data_frmt))
+	if (unlikely(cmpt_desc->err))
 		return -1;
 
 	cmpt_buff_ptr = (char *)cmpt_buff;
diff --git a/QDMA/DPDK/drivers/net/qdma/qdma_user.h b/QDMA/DPDK/drivers/net/qdma/qdma_user.h
index 9c3de6f..c46a835 100755
--- a/QDMA/DPDK/drivers/net/qdma/qdma_user.h
+++ b/QDMA/DPDK/drivers/net/qdma/qdma_user.h
@@ -49,41 +49,16 @@
   * This structure is specific for the example design.
   * Processing of this ring happens in qdma_rxtx.c.
   */
-union qdma_ul_st_cmpt_ring {
+union __attribute__ ((packed)) qdma_ul_st_cmpt_ring {
 	volatile uint64_t data;
-	struct {
-		/* For 2018.2 IP, this field determines the
-		 * Standard or User format of completion entry
-		 */
-		volatile uint32_t	data_frmt:1;
-
-		/* This field inverts every time PIDX wraps
-		 * the completion ring
-		 */
-		volatile uint32_t	color:1;
-
-		/* Indicates that C2H engine encountered
-		 * a descriptor error
-		 */
-		volatile uint32_t	err:1;
-
-		/* Indicates that the completion packet
-		 * consumes descriptor in C2H ring
-		 */
-		volatile uint32_t	desc_used:1;
-
-		/* Indicates length of the data packet */
-		volatile uint32_t	length:16;
-
-		/* Reserved field */
-		volatile uint32_t	user_rsv:4;
-
-		/* User logic defined data of
-		 * length based on CMPT entry
-		 * length
-		 */
-		volatile uint8_t	user_def[];
-	};
+    struct __attribute__ ((packed)) {
+        volatile uint32_t rsvd:1;
+        volatile uint32_t color:1;
+        volatile uint32_t err:1;
+        volatile uint32_t rsvd2:29;
+        volatile uint32_t pkt_len:16;
+        volatile uint32_t pkt_id:16;
+    };
 };
 
 
@@ -129,10 +104,10 @@ struct __attribute__ ((packed)) qdma_ul_st_c2h_desc
 /** ST H2C Descriptor **/
 struct __attribute__ ((packed)) qdma_ul_st_h2c_desc
 {
-	volatile uint16_t	cdh_flags;
-	volatile uint16_t	pld_len;
+	volatile uint16_t	meta_pkt_len;
+	volatile uint16_t	meta_unused;
 	volatile uint16_t	len;
-	volatile uint16_t	flags;
+	volatile uint16_t	rsvd;
 	volatile uint64_t	src_addr;
 };
 
